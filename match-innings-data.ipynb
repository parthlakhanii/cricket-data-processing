{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import calmap\n",
    "import os\n",
    "import re\n",
    "import json as JSON\n",
    "PATH=''\n",
    "\n",
    "def checkDirectory():\n",
    "    if os.path.isdir('./jsons')==False:\n",
    "        !mkdir jsons    \n",
    "\n",
    "def initialise():\n",
    "    checkDirectory()\n",
    "    return './datasets/'\n",
    "\n",
    "    \n",
    "PATH=initialise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match:odi\n",
      "Match:t20\n",
      "Match:test\n",
      "Inning:odi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\envs\\anomaly-detection\\lib\\site-packages\\ipykernel_launcher.py:22: DtypeWarning: Columns (1,2,3,6,7,8,9,17,18,20,21,22,26,27) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inning:t20\n",
      "Inning:test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\envs\\anomaly-detection\\lib\\site-packages\\ipykernel_launcher.py:22: DtypeWarning: Columns (1,2,3,6,7,8,9,10,17) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177096\n",
      "11702428\n"
     ]
    }
   ],
   "source": [
    "def load_match_data(filenames):\n",
    "    match_regex = re.compile(r'^(?:.*)_match.csv$')\n",
    "    matches = [m for m in map(match_regex.match, filenames) if m is not None]\n",
    "    for match in matches:\n",
    "        match_type = re.sub('\\_match.csv$', '', match.group(0))\n",
    "        print(\"Match:\"+match_type)\n",
    "        dataset = pd.read_csv(PATH+match.group(0))\n",
    "        dataset.insert(2, \"type\", match_type)\n",
    "        yield dataset\n",
    "\n",
    "def load_innings_data(filenames):\n",
    "    inning_regex = re.compile(r'^(?:.*)_innings.csv$')\n",
    "    innings = [m for m in map(inning_regex.match, filenames) if m is not None]\n",
    "    for inning in innings:\n",
    "        inning_type = re.sub('\\_innings.csv$', '', inning.group(0))\n",
    "        print(\"Inning:\"+inning_type)\n",
    "        dataset = pd.read_csv(PATH+inning.group(0))\n",
    "        dataset.insert(2, \"type\", inning_type)\n",
    "        yield dataset\n",
    "\n",
    "data_match=pd.concat(load_match_data(os.listdir(PATH)))\n",
    "data_innings=pd.concat(load_innings_data(os.listdir(PATH)))\n",
    "print(data_match.size)\n",
    "print(data_innings.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset = pd.merge(data_innings,data_match,on=['Date','Ground'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateName(string1=\"\",string2=\"\",string3=\"\"):\n",
    "    string=string1+'_'+string2+'_'+string3\n",
    "    string=re.sub('-+', '_', string)\n",
    "    string=re.sub('\\s+', '_', string)\n",
    "    return string\n",
    "def writeToFile(jsonObject,name):\n",
    "    checkDirectory()\n",
    "    with open('./jsons/'+name+'.json', 'w') as outfile:\n",
    "        JSON.dump(jsonObject, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeUnnecessaryCountryData(dataset):\n",
    "    countries=['Afghanistan','Zimbabwe']\n",
    "    for country in countries:\n",
    "        dataset=dataset[dataset['Country_x']!=country]\n",
    "        dataset=dataset[dataset['Country_y']!=country]        \n",
    "    return dataset\n",
    "def updateCommentedCode(df):\n",
    "    df=df[df['Match Year']==2017]\n",
    "    df=df[df['Match Month']=='Jan']\n",
    "    dates=df['Date'].unique()  \n",
    "    matches=df['Match'].unique()  \n",
    "    date=dates[0]\n",
    "    match=matches[0]\n",
    "    df=df[df['Date']==date]\n",
    "    df=df[df['Match']==match]\n",
    "    df=df[df['Innings Number']=='2']\n",
    "    df\n",
    "    df=df.sort_values('Innings Number',ascending=True)\n",
    "    return df\n",
    "    \n",
    "def generateDataOfMatch(df):\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df['Date'] = df['Date'].dt.strftime('%Y-%m-%d')\n",
    "    df=df[[\"Innings Player\",\"Innings Runs Scored Num\",\"type_x\",\"Innings Batted Flag\",\"Innings Batting Strike Rate\",\"Innings Number\",\"Opposition\",\"Ground\",\"Date\",\"Country_x\",\"Country_y\",\"Innings Overs Bowled\",\"Innings Bowled Flag\",\"Innings Runs Conceded\",\"Innings Wickets Taken\",\"Innings Economy Rate\",\"Result\",\"Margin\",\"Match\",\"Home/Away\",\"Match Month\",\"Match Year\",\"Match Period\"]]\n",
    "    df=removeUnnecessaryCountryData(df)\n",
    "    df=df[df['Home/Away']=='Home']\n",
    "    df.fillna(0,inplace=True)\n",
    "    df['Innings Runs Scored Num'].fillna(0,inplace=True)\n",
    "    df['Innings Runs Scored Num'].replace(to_replace =\"-\", value =0,inplace=True)\n",
    "#     df.to_csv('hjk.csv')\n",
    "    match_array=[]\n",
    "    for key,group_df in df.groupby(['Match','Date','Ground','Result','Margin','type_x']):\n",
    "            json={}\n",
    "            json['match']=key[0]\n",
    "            teams=key[0].split(' v ')\n",
    "            json['team_1']=teams[0]\n",
    "            json['team_2']=teams[1]\n",
    "            json['date']=key[1]\n",
    "            json['ground']=key[2]\n",
    "            json['type']=key[5]\n",
    "            innings_array=[]\n",
    "            group_df = group_df.sort_values(by='Innings Number', ascending=True)\n",
    "            for subkey,subgroup_df in group_df.groupby(['Innings Number']):\n",
    "                innings={}\n",
    "                innings['number']=subkey[0]\n",
    "                player_array=[]\n",
    "                for index, player_individual in subgroup_df.iterrows():\n",
    "                    player={}\n",
    "                    batting={}\n",
    "                    bowling={}\n",
    "                    player['name']=player_individual['Innings Player']\n",
    "                    player['country']=player_individual['Country_x']\n",
    "                    batting['runs']=player_individual['Innings Runs Scored Num']\n",
    "                    bowling['runs_given']=player_individual['Innings Runs Conceded']\n",
    "                    bowling['economy_rate']=player_individual['Innings Economy Rate']                \n",
    "                    bowling['over_bowled']=player_individual['Innings Overs Bowled']\n",
    "                    bowling['wicket']=player_individual['Innings Wickets Taken']\n",
    "                    batting['batted']=True if (player_individual['Innings Batted Flag']==1) else False\n",
    "                    bowling['bowled']=True if (player_individual['Innings Bowled Flag']==1) else False\n",
    "                    batting['strike_rate']=player_individual['Innings Batting Strike Rate']\n",
    "                    player['batting']=batting\n",
    "                    player['bowling']=bowling\n",
    "                    player['innings']=player_individual['Innings Number']\n",
    "                    player_array.append(player)\n",
    "                innings['players']=player_array\n",
    "                innings_array.append(innings)                \n",
    "            json['innings']=innings_array\n",
    "            writeToFile(json,generateName(key[0],key[1],key[2]))\n",
    "            match_array.append(json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "generateDataOfMatch(merged_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
